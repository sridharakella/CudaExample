{
 "cells":[
  {
   "cell_type":"markdown",
   "source":[
    "# JYPTERCUDAEXAMPLE"
   ],
   "attachments":{},
   "metadata":{
    "datalore":{
     "node_id":"JYPTERCUDAEXAMPLE",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "sheet_delimiter":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import torch\n",
    "\n",
    "torch.cuda.is_available() # if the devide as cuda available\n",
    "\n",
    "\n"
   ],
   "execution_count":8,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "False"
      ]
     },
     "metadata":{},
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"4qBddoVnMv3MBvq7hxG781",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Check if the device has cuda available\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.init()\n",
    "else:\n",
    "    print(\"Cuda is not available on this device.\")"
   ],
   "execution_count":12,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Cuda is not available on this device.\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"9Ra9Y61oh9tSYzXJ73s4H5",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Check if CUDA is available before attempting to use it\n",
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        print(torch.cuda.current_device())\n",
    "        print(torch.cuda.device_count())\n",
    "    except AssertionError as error:\n",
    "        print(f\"Error occurred: {error}\")\n",
    "else:\n",
    "    print(\"CUDA is not available on this device.\")"
   ],
   "execution_count":14,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "CUDA is not available on this device.\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"ZcABx17oTme4OuMKa0xNbq",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "torch.cuda.memory_allocated()"
   ],
   "execution_count":15,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "0"
      ]
     },
     "metadata":{},
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"E6kHJtAeLsEidddfZjKXVI",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "torch.cuda.memory_cached() #  speeds up memory allocation to tensors and also deallocating\n",
    "torch.cuda.memory_reserved() # "
   ],
   "execution_count":17,
   "outputs":[
    {
     "name":"stderr",
     "text":[
      "<ipython-input-17-093c6b25722f>:1: FutureWarning: `torch.cuda.memory_cached` has been renamed to `torch.cuda.memory_reserved`\n",
      "  torch.cuda.memory_cached()\n"
     ],
     "output_type":"stream"
    },
    {
     "data":{
      "text\/plain":[
       "0"
      ]
     },
     "metadata":{},
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"yXZD8CuXNKOCWIque1tw21",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[],
   "execution_count":null,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"R3enoFthHnGd7DWl58Y7pS",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "cuda = torch.device('cuda')"
   ],
   "execution_count":18,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"g7slFmR532FPJEvjtScQlO",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "torch.device('cuda')"
   ],
   "execution_count":20,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "device(type='cuda')"
      ]
     },
     "metadata":{},
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"tL6cfDOlbSX3dt4xERhySg",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "cuda0 =torch.device('cuda:0')\n",
    "cuda1=torch.device('cuda:1')\n",
    "cuda2=torch.device('cuda:2')"
   ],
   "execution_count":21,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"Is2tNzcarw6jhjQ73uXxus",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "x= torch.tensor([10.,20.]) #by default created on CPU rather than GPU"
   ],
   "execution_count":23,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"vwJ3Lcp2tpSCrz3eTgsH8S",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        x = torch.tensor([10.,20.], device='cuda:0') # this line  will instiate on GPU\n",
    "    except AssertionError as error:\n",
    "        print(f\"Error occurred: {error}\")\n",
    "else:\n",
    "    print(\"CUDA is not available on this device. Creating tensor on CPU.\")\n",
    "    x = torch.tensor([10.,20.])  # by default created on CPU rather than GPU"
   ],
   "execution_count":null,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"12Z1RRBwVhzI84Runbeacy",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        # Attempt to copy the tensor to CUDA\n",
    "        y = x.cuda()\n",
    "    except AssertionError as error:\n",
    "        print(f\"Error occurred: {error}\")\n",
    "else:\n",
    "    print(\"CUDA is not available on this device. Keeping tensor on CPU.\")\n",
    "    y = x"
   ],
   "execution_count":null,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"UPPjQGPXykWWgnYl8YuyOj",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Check if more than one CUDA device is available\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    try:\n",
    "        print('outside the context',torch.cuda.current_device())\n",
    "        with torch.cuda.device(1) : # changing the cuda device to 1 , You change the cuda device.\n",
    "            print('inside the context', torch.cuda.current_device())\n",
    "        print('outside the context',torch.cuda.current_device())\n",
    "    except AssertionError as error:\n",
    "        print(f\"Error occurred: {error}\")\n",
    "else:\n",
    "    print(\"More than one CUDA device is not available on this device.\")"
   ],
   "execution_count":27,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "More than one CUDA device is not available on this device.\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"9WEE6PVEXk3VKWrorucvkZ",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Check if CUDA is available and if more than one device is available\n",
    "if torch.cuda.is_available() and torch.cuda.device_count() > 1:\n",
    "    try:\n",
    "        with torch.cuda.device(1):\n",
    "            a = torch.tensor([10.,20.], device='cuda:1')\n",
    "            a0 = torch.tensor([10.,20.], device='cuda:0')\n",
    "            a1 = torch.tensor([10.,20.], device='cuda:1')\n",
    "    except RuntimeError as error:\n",
    "        print(f\"Error occurred: {error}\")\n",
    "else:\n",
    "    print(\"CUDA is not available or only one CUDA device is available. Creating tensors on CPU.\")\n",
    "    a = torch.tensor([10.,20.])\n",
    "    a0 = torch.tensor([10.,20.])\n",
    "    a1 = torch.tensor([10.,20.])"
   ],
   "execution_count":null,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"u4bl6mZSbK3kk9Iy7NOi1Q",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Check if CUDA is available and if more than one device is available\n",
    "if torch.cuda.is_available() and torch.cuda.device_count() > 1:\n",
    "    try:\n",
    "        with torch.cuda.device(1):\n",
    "            a = torch.tensor([10.,20.], device='cuda:1')\n",
    "            a0 = torch.tensor([10.,20.], device='cuda:0')\n",
    "            a1 = torch.tensor([10.,20.], device='cuda:1')\n",
    "    except RuntimeError as error:\n",
    "        print(f\"Error occurred: {error}\")\n",
    "else:\n",
    "    print(\"CUDA is not available or only one CUDA device is available. Creating tensors on CPU.\")\n",
    "    a = torch.tensor([10.,20.])\n",
    "    a0 = torch.tensor([10.,20.])\n",
    "    a1 = torch.tensor([10.,20.])\n",
    "\n",
    "# Ensure a0 is created\n",
    "if 'a0' not in locals():\n",
    "    a0 = torch.tensor([10.,20.])\n",
    "\n",
    "b1 = a0.to(device=cuda1) # how to accept the tensor from one cuda 1 to cuda 0. You can't run \n",
    "# sum_a = a+ a0 ( you can run the a tensor from tensor 1 and tensor 0 , unless you copy one tensor to other tensor and execute )"
   ],
   "execution_count":null,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"NeNt6zdqLvxCec9aBRPfjB",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "torch.cuda.memory_cached()\n",
    "torch.cuda.empty_cache()"
   ],
   "execution_count":30,
   "outputs":[
    {
     "name":"stderr",
     "text":[
      "<ipython-input-30-4440d245e053>:1: FutureWarning: `torch.cuda.memory_cached` has been renamed to `torch.cuda.memory_reserved`\n",
      "  torch.cuda.memory_cached()\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"0Aw4e4ccVVZWt6FJwH6BT1",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "preserve_context= x.new_full"
   ],
   "execution_count":32,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"ZhieQeSQaZfk8W3ZWVh5KO",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# Sheet 2"
   ],
   "attachments":{},
   "metadata":{
    "datalore":{
     "node_id":"Sheet 2",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "sheet_delimiter":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# GRADIENT DECIENT ON NEURAL NETWORK"
   ],
   "execution_count":null,
   "outputs":[],
   "metadata":{
    "datalore":{
     "node_id":"3gazAc4TOWxXsJ7iMQJLSi",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  }
 ],
 "metadata":{
  "kernelspec":{
   "display_name":"Python",
   "language":"python",
   "name":"python"
  },
  "datalore":{
   "computation_mode":"JUPYTER",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[],
   "report_row_ids":[],
   "version":3
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}